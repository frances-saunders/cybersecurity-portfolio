{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Log Anomaly Detection â€“ Training Notebook\n",
    "\n",
    "This notebook trains an Isolation Forest on normal logs and evaluates anomalies on a candidate log file. No plaintext secrets are embedded. Any thresholds can be pulled from a vault or environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, statistics\n",
    "from typing import List, Dict, Any, Optional\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "CLF_REGEX = re.compile(r'(\\S+)\\s+\\S+\\s+\\S+\\s+\\[([^\\]]+)\\]\\s+\"(\\S+)\\s+(\\S+)\\s+([^\\\"]+)\"\\s+(\\d{3})\\s+(\\S+)\\s+\"([^\\\"]*)\"\\s+\"([^\\\"]*)\"')\n",
    "SUSPICIOUS_TOKENS = [\"union\",\"select\",\"drop\",\"sleep(\",\"' or '1'='1\",\"%27\",\"../\",\";--\",\"xp_cmdshell\",\"<script\",\"benchmark(\",\"load_file\",\"outfile\"]\n",
    "\n",
    "def shannon_entropy(s: str) -> float:\n",
    "    if not s: return 0.0\n",
    "    freq = {}\n",
    "    for ch in s: freq[ch] = freq.get(ch,0)+1\n",
    "    ent = 0.0\n",
    "    for c in freq.values():\n",
    "        p = c/len(s)\n",
    "        ent -= p*math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def parse_line(line: str):\n",
    "    m = CLF_REGEX.match(line.strip())\n",
    "    if not m: return None\n",
    "    ip, ts, method, path, proto, status, bts, ref, ua = m.groups()\n",
    "    status = int(status)\n",
    "    bts = 0 if bts == '-' else int(bts)\n",
    "    return dict(ip=ip, ts=ts, method=method, path=path, proto=proto, status=status, bytes=bts, ref=ref, ua=ua)\n",
    "\n",
    "def extract_features(d: Dict[str, Any]):\n",
    "    path = d.get('path',''); ua = d.get('ua',''); method = d.get('method','')\n",
    "    method_map = {\"GET\":0,\"POST\":1,\"PUT\":2,\"DELETE\":3,\"PATCH\":4,\"HEAD\":5,\"OPTIONS\":6}\n",
    "    method_id = method_map.get(method.upper(), -1)\n",
    "    suspicious = any(tok in path.lower() for tok in SUSPICIOUS_TOKENS)\n",
    "    qlen = len(path.split('?',1)[1]) if '?' in path else 0\n",
    "    return [float(method_id), float(d.get('status',0)), float(d.get('bytes',0)), float(len(path)), float(qlen), float(shannon_entropy(path)), float(shannon_entropy(ua)), 1.0 if suspicious else 0.0]\n",
    "\n",
    "def load_dataset(path: str):\n",
    "    X, raw = [], []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            d = parse_line(line)\n",
    "            if not d: continue\n",
    "            X.append(extract_features(d))\n",
    "            raw.append(line.rstrip('\\n'))\n",
    "    return X, raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Set the paths to your normal and candidate logs within this lab's `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL = '../data/normal_traffic.log'\n",
    "CANDIDATE = '../data/anomalous_traffic.log'\n",
    "X_train, _ = load_dataset(NORMAL)\n",
    "X_test, raw = load_dataset(CANDIDATE)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Isolation Forest and score candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(n_estimators=200, contamination='auto', random_state=42)\n",
    "iso.fit(X_train)\n",
    "scores = -iso.decision_function(X_test)  # higher = more anomalous\n",
    "mu = statistics.mean(scores)\n",
    "sd = statistics.pstdev(scores) or 1.0\n",
    "zs = [(s - mu)/sd for s in scores]\n",
    "sum(1 for z in zs if z >= 1.5), len(zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect top anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(zip(zs, raw))\n",
    "pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "for i,(z,line) in enumerate(pairs[:10]):\n",
    "    print(f\"{i+1:02d}  z={z:.3f}  {line}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.10" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
